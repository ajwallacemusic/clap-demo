# CLAP Demo App
## Semantic Search on Audio Sources
This demo app demonstrates how to implement the CLAP model to perform text to audio search, audio label classification and audio to audio search.

Main Components of this demo are the CLAP notebook, which installs dependencies and starts up an opensearch cluster via the docker-compose file, and the streamlit app, which demonstrates how to record, index, and search audio.


For more information about CLAP, checkout the github page, the research article, or the hugging face model page.