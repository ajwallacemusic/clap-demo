{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6mp0E5YfOWv",
        "outputId": "f3528301-0a72-4f5a-fc69-9b3ffed96862"
      },
      "outputs": [],
      "source": [
        "# install and import dependencies\n",
        "\n",
        "%pip install datasets transformers wget opensearch-py envtpl gdown librosa torch torchvision torchaudio soundfile ipywidgets pyaudio\n",
        "\n",
        "from transformers import pipeline, ClapModel, ClapProcessor, AutoTokenizer\n",
        "import IPython as ip\n",
        "import librosa\n",
        "import json\n",
        "import csv\n",
        "from opensearchpy import OpenSearch\n",
        "from opensearchpy.helpers import bulk\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker-compose up -d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xxKx95q376F",
        "outputId": "91c54162-61ea-4d01-980d-235f75fbcfc6"
      },
      "outputs": [],
      "source": [
        "# check opensearch connection\n",
        "\n",
        "!curl -X GET http://localhost:9200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sB9cQYyKPe1",
        "outputId": "a05d05ae-1688-413f-9916-0248b9c8efa5"
      },
      "outputs": [],
      "source": [
        "# create opensearch client\n",
        "\n",
        "host = 'localhost'\n",
        "port = 9200\n",
        "\n",
        "# Create the client with ssl and auth disabled, NOT to be used for production!\n",
        "client = OpenSearch(\n",
        "    hosts = [{'host': host, 'port': port}],\n",
        "    http_compress = True, # enables gzip compression for request bodies\n",
        "    use_ssl = False,\n",
        "    verify_certs = False,\n",
        "    ssl_assert_hostname = False,\n",
        "    ssl_show_warn = False,\n",
        ")\n",
        "\n",
        "print(client.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGejEiTyG-hO",
        "outputId": "14b6ff90-172d-4265-f0af-1e3d65558d94"
      },
      "outputs": [],
      "source": [
        "# Create clap index if it doesn't already exist.\n",
        "\n",
        "index_name = 'clap'\n",
        "\n",
        "response = client.indices.exists(index=index_name)\n",
        "print('\\nDoes Index already exist?')\n",
        "print(response)\n",
        "if response == True:\n",
        "  print('Skipping creating index')\n",
        "else:\n",
        "  # generate the index mappings and settings and create the index\n",
        "  f = open('./clap_mapping.json')\n",
        "  index_mappings_and_settings = json.load(f)\n",
        "\n",
        "  response = client.indices.create(index_name, body=index_mappings_and_settings)\n",
        "  print('\\nCreating index:')\n",
        "  print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6t-7gNdDDbm"
      },
      "outputs": [],
      "source": [
        "# init ML processors/models/tokenizers\n",
        "audio_classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/larger_clap_music_and_speech\")\n",
        "model = ClapModel.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
        "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"laion/larger_clap_music_and_speech\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to create audio embedding\n",
        "\n",
        "def embed_audio(filepath):\n",
        "    y, sr = librosa.load(filepath)\n",
        "    inputs = processor(audios=y, return_tensors=\"pt\", sampling_rate=48000)\n",
        "    audio_embed = model.get_audio_features(**inputs)\n",
        "    arr = audio_embed.detach().numpy()\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List to store documents for bulk indexing\n",
        "bulk_docs = []\n",
        "# es bulk batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Function to perform bulk indexing\n",
        "def bulk_index_documents(documents):\n",
        "    actions = []\n",
        "    for doc in documents:\n",
        "        action = {\n",
        "            \"_index\": index_name,\n",
        "            \"_source\": doc\n",
        "        }\n",
        "        actions.append(action)\n",
        "    \n",
        "    bulk(client, actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FMA Audio Set\n",
        "\n",
        "# define range for fma sub directories\n",
        "start_fma_directory = 0\n",
        "end_fma_directory = 155  \n",
        "\n",
        "# Define the common part of fma directory path\n",
        "base_directory = '../audio_data/fma/data/fma_small/'\n",
        "\n",
        "# csv with metadata for fma tracks\n",
        "fma_metadata = '../audio_data/fma/data/fma_metadata/raw_tracks.csv'\n",
        "\n",
        "\n",
        "# Read CSV file into a dictionary for easy lookup\n",
        "fma_mapping = {}\n",
        "with open(fma_metadata, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        fma_mapping[row['track_id']] = {'artist': row['artist_name'], 'title': row['track_title'], 'album': row['album_title'], 'genres': row['track_genres']}\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "for directory_number in range(start_fma_directory, end_fma_directory + 1):\n",
        "    # Construct the directory path\n",
        "    fma_directory = os.path.join(base_directory, f\"{directory_number:03d}\")\n",
        "\n",
        "    for filename in os.listdir(fma_directory):\n",
        "        track_file = filename.lstrip('0')\n",
        "        track_id = track_file[:-4]\n",
        "\n",
        "        genres_arr = fma_mapping[track_id]['genres'].replace(\"'\", '\"')\n",
        "        genres_j = json.loads(genres_arr)\n",
        "        genres = [genre['genre_title'] for genre in genres_j]\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            filepath = os.path.join(fma_directory, filename)\n",
        "            print(\"Processing:\", filepath)\n",
        "            print(\"track_id: \", track_id)\n",
        "\n",
        "            # y, sr = librosa.load(filepath)\n",
        "            # inputs = processor(audios=y, return_tensors=\"pt\", sampling_rate=48000)\n",
        "            # audio_embed = model.get_audio_features(**inputs)\n",
        "            # arr = audio_embed.detach().numpy()\n",
        "\n",
        "            arr = embed_audio(filepath)\n",
        "\n",
        "            doc = {\n",
        "                \"audio_embedding\": arr[0],\n",
        "                \"audio_set\": \"fma\",\n",
        "                \"title\": fma_mapping[track_id]['title'],\n",
        "                \"artist\": fma_mapping[track_id]['artist'],\n",
        "                \"album\": fma_mapping[track_id]['album'],\n",
        "                \"track_id\": track_id,\n",
        "                \"genres\": genres,\n",
        "                \"filepath\": filepath,\n",
        "            }\n",
        "\n",
        "            # Add document to bulk indexing list\n",
        "            bulk_docs.append(doc)\n",
        "            \n",
        "            # Perform bulk indexing if batch size is reached\n",
        "            if len(bulk_docs) == batch_size:\n",
        "                bulk_index_documents(bulk_docs)\n",
        "                bulk_docs = []\n",
        "                \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vocal Imitations Audio Set\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "vocal_imitations_directory = '../audio_data/vocal_imitations/included/'\n",
        "for filename in os.listdir(vocal_imitations_directory):\n",
        "    track_id = filename[:-4]\n",
        "\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(vocal_imitations_directory, filename)\n",
        "        print(\"Processing:\", filepath)\n",
        "        print(\"track_id: \", track_id)\n",
        "\n",
        "        # y, sr = librosa.load(filepath)\n",
        "        # inputs = processor(audios=y, return_tensors=\"pt\", sampling_rate=48000)\n",
        "        # audio_embed = model.get_audio_features(**inputs)\n",
        "        # arr = audio_embed.detach().numpy()\n",
        "\n",
        "        arr = embed_audio(filepath)\n",
        "\n",
        "        doc = {\n",
        "            \"audio_embedding\": arr[0],\n",
        "            \"audio_set\": \"vocal_imitations\",\n",
        "            \"track_id\": track_id,\n",
        "            \"filepath\": filepath,\n",
        "        }\n",
        "\n",
        "        # Add document to bulk indexing list\n",
        "        bulk_docs.append(doc)\n",
        "        \n",
        "        # Perform bulk indexing if batch size is reached\n",
        "        if len(bulk_docs) == batch_size:\n",
        "            bulk_index_documents(bulk_docs)\n",
        "            bulk_docs = []\n",
        "            \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUSS Audio Set\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "fuss_directory = '../audio_data/FUSS/source_pure/fsd_data/train/sound'\n",
        "for filename in os.listdir(fuss_directory):\n",
        "    track_id = filename[:-4]\n",
        "\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(fuss_directory, filename)\n",
        "        print(\"Processing:\", filepath)\n",
        "        print(\"track_id: \", track_id)\n",
        "\n",
        "        arr = embed_audio(filepath)\n",
        "\n",
        "        doc = {\n",
        "            \"audio_embedding\": arr[0],\n",
        "            \"audio_set\": \"fuss\",\n",
        "            \"track_id\": track_id,\n",
        "            \"filepath\": filepath,\n",
        "        }\n",
        "\n",
        "        # Add document to bulk indexing list\n",
        "        bulk_docs.append(doc)\n",
        "        \n",
        "        # Perform bulk indexing if batch size is reached\n",
        "        if len(bulk_docs) == batch_size:\n",
        "            bulk_index_documents(bulk_docs)\n",
        "            bulk_docs = []\n",
        "            \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiIyGGN9fcAO"
      },
      "outputs": [],
      "source": [
        "# Check how many docs have audio_embedding\n",
        "query = {\n",
        "  'size': 5,\n",
        "  'query': {\n",
        "    'exists': {'field': 'audio_embedding'}\n",
        "  }\n",
        "}\n",
        "\n",
        "response = client.search(\n",
        "    body = query,\n",
        "    index = index_name\n",
        ")\n",
        "print('\\nSearch results:')\n",
        "print(response['hits']['total'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVasMxTwz_Sz"
      },
      "outputs": [],
      "source": [
        "# similarity search with text input against audio_embeddings\n",
        "\n",
        "query = input('type a search query: ')\n",
        "text_data = tokenizer([query], padding=True, return_tensors=\"pt\")\n",
        "text_embed = model.get_text_features(**text_data)\n",
        "text_arr = text_embed.detach().numpy()[0]\n",
        "\n",
        "# Search for the document.\n",
        "query = {\n",
        "  'size': 5,\n",
        "  'query': {\n",
        "    'knn': {\n",
        "        'audio_embedding': {\n",
        "            'k': 10,\n",
        "            'vector': text_arr\n",
        "        }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "response = client.search(\n",
        "    body = query,\n",
        "    index = index_name\n",
        ")\n",
        "print('\\nSearch results:')\n",
        "hits = response['hits']['hits']\n",
        "\n",
        "def displayResults(hits):\n",
        "  for hit in hits:\n",
        "    if 'title' in hit['_source'] and 'genres' in hit['_source']:\n",
        "      ip.display.display(hit['_source']['title'], hit['_source']['genres'])\n",
        "    ip.display.display(hit['_score'])\n",
        "    filepath = hit['_source']['filepath']\n",
        "    ip.display.display(ip.display.Audio(filepath))\n",
        "\n",
        "displayResults(hits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pyaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "import pyaudio\n",
        "import wave\n",
        "import threading\n",
        "\n",
        "recording = False\n",
        "audio_data = []\n",
        "filename = input('enter a name for the recording')\n",
        "ip.display.display(\"filename: \" + filename + \".wav\")\n",
        "\n",
        "def record_audio():\n",
        "    global recording\n",
        "    global audio_data\n",
        "\n",
        "    CHUNK = 1024\n",
        "    FORMAT = pyaudio.paInt16\n",
        "    CHANNELS = 1\n",
        "    RATE = 44100\n",
        "\n",
        "    audio = pyaudio.PyAudio()\n",
        "\n",
        "    # Enumerate available audio devices\n",
        "    num_devices = audio.get_device_count()\n",
        "    devices = [audio.get_device_info_by_index(i) for i in range(num_devices)]\n",
        "\n",
        "    # Find the index of the desired device by name\n",
        "    desired_device_name = 'MacBook Pro Microphone'\n",
        "    desired_device_index = None\n",
        "    for i, device in enumerate(devices):\n",
        "        if device['name'] == desired_device_name:\n",
        "            desired_device_index = i\n",
        "            break\n",
        "\n",
        "    stream = audio.open(format=FORMAT,\n",
        "                        channels=CHANNELS,\n",
        "                        rate=RATE,\n",
        "                        input=True,\n",
        "                        input_device_index=desired_device_index,\n",
        "                        frames_per_buffer=CHUNK)\n",
        "\n",
        "    audio_data = []\n",
        "    print(\"Recording...\")\n",
        "\n",
        "    while recording:\n",
        "        data = stream.read(CHUNK)\n",
        "        audio_data.append(data)\n",
        "\n",
        "    print(\"Finished recording\")\n",
        "\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    audio.terminate()\n",
        "\n",
        "def on_button_clicked(button):\n",
        "    global recording\n",
        "    global audio_data\n",
        "\n",
        "    if button.description == \"Record\":\n",
        "        button.description = \"Stop\"\n",
        "        recording = True\n",
        "        threading.Thread(target=record_audio).start()\n",
        "        \n",
        "    else:\n",
        "        button.description = \"Record\"\n",
        "        recording = False\n",
        "\n",
        "        if audio_data:\n",
        "            wf = wave.open(f\"./recordings/{filename}.wav\", 'wb')\n",
        "            wf.setnchannels(1)\n",
        "            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(pyaudio.paInt16))\n",
        "            wf.setframerate(44100)\n",
        "            wf.writeframes(b''.join(audio_data))\n",
        "            wf.close()\n",
        "        else:\n",
        "            print(\"No audio data recorded.\")\n",
        "\n",
        "# Create the button widget\n",
        "record_button = widgets.Button(description=\"Record\")\n",
        "\n",
        "# Define the button click event handler\n",
        "record_button.on_click(on_button_clicked)\n",
        "\n",
        "# Display the button\n",
        "display(record_button)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
