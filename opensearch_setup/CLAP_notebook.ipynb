{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6mp0E5YfOWv",
        "outputId": "f3528301-0a72-4f5a-fc69-9b3ffed96862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (4.39.3)\n",
            "Requirement already satisfied: opensearch-py in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (2.5.0)\n",
            "Requirement already satisfied: librosa in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (0.10.1)\n",
            "Requirement already satisfied: torch in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (0.17.2)\n",
            "Requirement already satisfied: torchaudio in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (2.2.2)\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: filelock in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (2024.4.16)\n",
            "Requirement already satisfied: requests in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: urllib3<2,>=1.26.18 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from opensearch-py) (1.26.18)\n",
            "Requirement already satisfied: six in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from opensearch-py) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from opensearch-py) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from opensearch-py) (2024.2.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (1.13.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (0.59.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: sympy in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from torch) (2024.3.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /Users/ajwallace/develop/clap-demo/.venv/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp39-cp39-macosx_14_0_arm64.whl size=25699 sha256=0bfe03f4aa3fe534a642710405dfb19810dbac759a39cdce08be478d54823fd6\n",
            "  Stored in directory: /Users/ajwallace/Library/Caches/pip/wheels/28/d3/62/6ad369dc09fe82e1c9ceb83601a800eb305b901df7789aa550\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# install and import dependencies\n",
        "\n",
        "%pip install transformers opensearch-py librosa torch torchvision torchaudio pyaudio\n",
        "\n",
        "from transformers import pipeline, ClapModel, ClapProcessor, AutoTokenizer\n",
        "import IPython as ip\n",
        "import librosa\n",
        "import json\n",
        "import csv\n",
        "from opensearchpy import OpenSearch\n",
        "from opensearchpy.helpers import bulk\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!docker-compose up -d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xxKx95q376F",
        "outputId": "91c54162-61ea-4d01-980d-235f75fbcfc6"
      },
      "outputs": [],
      "source": [
        "# check opensearch connection\n",
        "\n",
        "!curl -X GET http://localhost:9200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sB9cQYyKPe1",
        "outputId": "a05d05ae-1688-413f-9916-0248b9c8efa5"
      },
      "outputs": [],
      "source": [
        "# create opensearch client\n",
        "\n",
        "host = 'localhost'\n",
        "port = 9200\n",
        "\n",
        "# Create the client with ssl and auth disabled, NOT to be used for production!\n",
        "client = OpenSearch(\n",
        "    hosts = [{'host': host, 'port': port}],\n",
        "    http_compress = True, # enables gzip compression for request bodies\n",
        "    use_ssl = False,\n",
        "    verify_certs = False,\n",
        "    ssl_assert_hostname = False,\n",
        "    ssl_show_warn = False,\n",
        ")\n",
        "\n",
        "print(client.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGejEiTyG-hO",
        "outputId": "14b6ff90-172d-4265-f0af-1e3d65558d94"
      },
      "outputs": [],
      "source": [
        "# Create clap index if it doesn't already exist.\n",
        "\n",
        "index_name = 'clap'\n",
        "\n",
        "response = client.indices.exists(index=index_name)\n",
        "print('\\nDoes Index already exist?')\n",
        "print(response)\n",
        "if response == True:\n",
        "  print('Skipping creating index')\n",
        "else:\n",
        "  # generate the index mappings and settings and create the index\n",
        "  f = open('./clap_mapping.json')\n",
        "  index_mappings_and_settings = json.load(f)\n",
        "\n",
        "  response = client.indices.create(index_name, body=index_mappings_and_settings)\n",
        "  print('\\nCreating index:')\n",
        "  print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6t-7gNdDDbm"
      },
      "outputs": [],
      "source": [
        "# init ML processors/models/tokenizers\n",
        "audio_classifier = pipeline(task=\"zero-shot-audio-classification\", model=\"laion/larger_clap_music_and_speech\")\n",
        "model = ClapModel.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
        "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_music_and_speech\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"laion/larger_clap_music_and_speech\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to create audio embedding\n",
        "\n",
        "def embed_audio(filepath):\n",
        "    y, sr = librosa.load(filepath)\n",
        "    inputs = processor(audios=y, return_tensors=\"pt\", sampling_rate=48000)\n",
        "    audio_embed = model.get_audio_features(**inputs)\n",
        "    arr = audio_embed.detach().numpy()\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List to store documents for bulk indexing\n",
        "bulk_docs = []\n",
        "# es bulk batch size\n",
        "batch_size = 100\n",
        "\n",
        "# Function to perform bulk indexing\n",
        "def bulk_index_documents(documents):\n",
        "    actions = []\n",
        "    for doc in documents:\n",
        "        action = {\n",
        "            \"_index\": index_name,\n",
        "            \"_source\": doc\n",
        "        }\n",
        "        actions.append(action)\n",
        "    \n",
        "    bulk(client, actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FMA Audio Set\n",
        "\n",
        "# define range for fma sub directories\n",
        "start_fma_directory = 134\n",
        "end_fma_directory = 155  \n",
        "\n",
        "# Define the common part of fma directory path\n",
        "base_directory = '../audio_data/fma/data/fma_small/'\n",
        "\n",
        "# csv with metadata for fma tracks\n",
        "fma_metadata = '../audio_data/fma/data/fma_metadata/raw_tracks.csv'\n",
        "\n",
        "\n",
        "# Read CSV file into a dictionary for easy lookup\n",
        "fma_mapping = {}\n",
        "with open(fma_metadata, 'r') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        fma_mapping[row['track_id']] = {'artist': row['artist_name'], 'title': row['track_title'], 'album': row['album_title'], 'genres': row['track_genres']}\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "for directory_number in range(start_fma_directory, end_fma_directory + 1):\n",
        "    # Construct the directory path\n",
        "    fma_directory = os.path.join(base_directory, f\"{directory_number:03d}\")\n",
        "\n",
        "    for filename in os.listdir(fma_directory):\n",
        "        track_file = filename.lstrip('0')\n",
        "        track_id = track_file[:-4]\n",
        "\n",
        "        genres_arr = fma_mapping[track_id]['genres'].replace(\"'\", '\"')\n",
        "        genres_j = json.loads(genres_arr)\n",
        "        genres = [genre['genre_title'] for genre in genres_j]\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            filepath = os.path.join(fma_directory, filename)\n",
        "            print(\"Processing:\", filepath)\n",
        "            print(\"track_id: \", track_id)\n",
        "\n",
        "            # y, sr = librosa.load(filepath)\n",
        "            # inputs = processor(audios=y, return_tensors=\"pt\", sampling_rate=48000)\n",
        "            # audio_embed = model.get_audio_features(**inputs)\n",
        "            # arr = audio_embed.detach().numpy()\n",
        "\n",
        "            arr = embed_audio(filepath)\n",
        "\n",
        "            doc = {\n",
        "                \"audio_embedding\": arr[0],\n",
        "                \"audio_set\": \"fma\",\n",
        "                \"title\": fma_mapping[track_id]['title'],\n",
        "                \"artist\": fma_mapping[track_id]['artist'],\n",
        "                \"album\": fma_mapping[track_id]['album'],\n",
        "                \"track_id\": track_id,\n",
        "                \"genres\": genres,\n",
        "                \"filepath\": filepath,\n",
        "            }\n",
        "\n",
        "            # Add document to bulk indexing list\n",
        "            bulk_docs.append(doc)\n",
        "            \n",
        "            # Perform bulk indexing if batch size is reached\n",
        "            if len(bulk_docs) == batch_size:\n",
        "                bulk_index_documents(bulk_docs)\n",
        "                bulk_docs = []\n",
        "                \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vocal Imitations Audio Set\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "vocal_imitations_directory = '../audio_data/vocal_imitations/included/'\n",
        "for filename in os.listdir(vocal_imitations_directory):\n",
        "    track_id = filename[:-4]\n",
        "\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(vocal_imitations_directory, filename)\n",
        "        print(\"Processing:\", filepath)\n",
        "        print(\"track_id: \", track_id)\n",
        "\n",
        "        arr = embed_audio(filepath)\n",
        "\n",
        "        doc = {\n",
        "            \"audio_embedding\": arr[0],\n",
        "            \"audio_set\": \"vocal_imitations\",\n",
        "            \"track_id\": track_id,\n",
        "            \"filepath\": filepath,\n",
        "        }\n",
        "\n",
        "        # Add document to bulk indexing list\n",
        "        bulk_docs.append(doc)\n",
        "        \n",
        "        # Perform bulk indexing if batch size is reached\n",
        "        if len(bulk_docs) == batch_size:\n",
        "            bulk_index_documents(bulk_docs)\n",
        "            bulk_docs = []\n",
        "            \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUSS Audio Set\n",
        "\n",
        "# Iterate over all audio files in the directory and generate es doc\n",
        "fuss_directory = '../audio_data/FUSS/source_pure/fsd_data/train/sound'\n",
        "for filename in os.listdir(fuss_directory):\n",
        "    track_id = filename[:-4]\n",
        "\n",
        "    if filename.endswith(\".wav\"):\n",
        "        filepath = os.path.join(fuss_directory, filename)\n",
        "        print(\"Processing:\", filepath)\n",
        "        print(\"track_id: \", track_id)\n",
        "\n",
        "        arr = embed_audio(filepath)\n",
        "\n",
        "        doc = {\n",
        "            \"audio_embedding\": arr[0],\n",
        "            \"audio_set\": \"fuss\",\n",
        "            \"track_id\": track_id,\n",
        "            \"filepath\": filepath,\n",
        "        }\n",
        "\n",
        "        # Add document to bulk indexing list\n",
        "        bulk_docs.append(doc)\n",
        "        \n",
        "        # Perform bulk indexing if batch size is reached\n",
        "        if len(bulk_docs) == batch_size:\n",
        "            bulk_index_documents(bulk_docs)\n",
        "            bulk_docs = []\n",
        "            \n",
        "# Index any remaining documents\n",
        "if bulk_docs:\n",
        "    bulk_index_documents(bulk_docs)\n",
        "\n",
        "print(\"Bulk indexing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiIyGGN9fcAO"
      },
      "outputs": [],
      "source": [
        "# Check how many docs have audio_embedding\n",
        "query = {\n",
        "  'size': 5,\n",
        "  'query': {\n",
        "    'exists': {'field': 'audio_embedding'}\n",
        "  }\n",
        "}\n",
        "\n",
        "response = client.search(\n",
        "    body = query,\n",
        "    index = index_name\n",
        ")\n",
        "print('\\nSearch results:')\n",
        "print(response['hits']['total'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVasMxTwz_Sz"
      },
      "outputs": [],
      "source": [
        "# similarity search with text input against audio_embeddings\n",
        "\n",
        "query = input('type a search query: ')\n",
        "text_data = tokenizer([query], padding=True, return_tensors=\"pt\")\n",
        "text_embed = model.get_text_features(**text_data)\n",
        "text_arr = text_embed.detach().numpy()[0]\n",
        "\n",
        "# Search for the document.\n",
        "query = {\n",
        "  'size': 5,\n",
        "  'query': {\n",
        "    'knn': {\n",
        "        'audio_embedding': {\n",
        "            'k': 10,\n",
        "            'vector': text_arr\n",
        "        }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "response = client.search(\n",
        "    body = query,\n",
        "    index = index_name\n",
        ")\n",
        "print('\\nSearch results:')\n",
        "hits = response['hits']['hits']\n",
        "\n",
        "def displayResults(hits):\n",
        "  for hit in hits:\n",
        "    if 'title' in hit['_source'] and 'genres' in hit['_source']:\n",
        "      ip.display.display(hit['_source']['title'], hit['_source']['genres'])\n",
        "    ip.display.display(hit['_score'])\n",
        "    filepath = hit['_source']['filepath']\n",
        "    ip.display.display(ip.display.Audio(filepath))\n",
        "\n",
        "displayResults(hits)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
